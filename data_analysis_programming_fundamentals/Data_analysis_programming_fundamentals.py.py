# -*- coding: utf-8 -*-
"""Paris.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QaOjLPBR-m-S7ajLI4qA2YNrmcEHNbjc

# **s**

# Programming for Data Analytics

Version Control

pandas 1.5.3

seaborn 0.12.2

matplotlib 3.7.2

scikit-learn 1.2.2

# **Programming for Data Analytics**

This project explores the application of Python in data analytics to investigate housing trends in Paris, utilising a comprehensive real estate dataset. The main objective is to employ programming skills to extract meaningful insights, with a particular focus on examining relationships between property price, number of bedrooms, number of floors, and total square footage. The study aligns with key learning outcomes, demonstrating a solid understanding of programming concepts (LO1), applying relevant tools and techniques for data preparation and analysis (LO2), and critically evaluating the analytical results (LO3). The approach includes data cleaning, transformation, statistical testing, and visual exploration to uncover patterns that may inform housing market predictions. By combining theoretical knowledge with practical coding in Python, this project aims to deliver clear, justified insights to support strategic decision-making for a real estate firm operating in the Paris housing market.

# **Loading the libraries**

Pandas is used to load and manage the data easily, especially for cleaning and analysis.

Seaborn helps create detailed and visually appealing graphs for deeper insights.

Matplotlib is used for general plotting—line graphs, bar charts, histograms, etc.

Google Colab Drive mount lets me access files stored in my Google Drive directly from the notebook.
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import drive
drive.mount('/content/drive/')

"""# **Dataset Loading**

df.head() loads up the first 5 rows of the data set, just to show that the data set is working

df.tail() with a number in the parentheses shows the last rows of the dataframe.
"""

# Load the Excel file to examine the dataset for Task 1.1
file_path = 'content/drive/MyDrive/Paris_housing_Data_Set_2_4050.xlsx'
df = pd.read_excel('/content/drive/MyDrive/Paris housing Data Set 2 4050.xlsx')
# #Show first 7 rows of the dataframe
# display(df.iloc[:, :7].head())
# # Show first 5 rows of the remaining 4 columns
# display(df.iloc[:, 7:].head())
df.head()

#Number of Data poiunt
df.shape

"""# **Statistical Analysis Before Cleaning**

The dataset contains 19,999 rows and 11 columns, mostly with float values. Several columns have missing data: price, bedrooms, bathrooms, and others have a few null entries. No object (string) types are present, making it clean in terms of data types but needing handling for nulls. This is a typical structure for numeric real estate data, fit for analysis after cleaning.

Descriptive stats show a wide range of values. For instance, price ranges significantly, indicating diverse property values. sqft_total and living_area_sqft also vary, showing big differences in house sizes. Standard deviations are high in many fields, which suggests outliers. Some mean values, like ~3.4 for bedrooms, align with typical house profiles. Cleaning will help refine these insights.
"""

# SHow the data statistics before cleaning
df.describe(())

"""# **Data Cleaning**

**Removing NaN Values**

Initially, the code prints "Before Cleaning!" and displays the count of missing values in each column using df.isnull().sum(), revealing data quality issues. Then, it creates a new dataframe (df_clean) by dropping all rows with missing values using dropna(). Finally, it prints "After Cleaning" and displays zero missing values in every column, confirming that all missing entries have been completely removed.
"""

# before and after cleaning
missing_before = df.isnull().sum()
missing_after = df.dropna().isnull().sum()

#Combine side by side
comparison_df = pd.concat([missing_before, missing_after], axis=1)
comparison_df.columns = ['Missing Before Cleaning', 'Missing After Cleaning']

# Display nicely
print("Missing Values Comparison")
display(comparison_df)

"""**Duplicate records Treatments**

Duplicates found accroos all 11 rows
"""

# Checking for duplicate records
print("Duplicates records: ", df.duplicated().sum())
print("After dropping duplicates!")
df.drop_duplicates(inplace=True)
print("Duplicates records: ", df.duplicated().sum())

"""**Checking for Outliers**

These boxplots illustrate distributions for price, bedrooms, total square footage, and floors. Outliers, shown as points beyond the whiskers, indicate data values outside typical ranges. For instance, extreme high prices and atypical bedroom counts reveal anomalies that warrant investigation, providing actionable insights for effective customer segmentation, demonstrating robust market segmentation.
"""

# Box plots to display outliers in 'price', 'bedrooms', 'sqft_total', and 'floors'
plt.figure(figsize=(12, 8))

# Price
plt.subplot(2, 2, 1)
sns.boxplot(x=df_clean['price'])
plt.title('Outliers in Price')

# Bedrooms
plt.subplot(2, 2, 2)
sns.boxplot(x=df_clean['bedrooms'])
plt.title('Outliers in Bedrooms')

# Sqft Total
plt.subplot(2, 2, 3)
sns.boxplot(x=df_clean['sqft_total'])
plt.title('Outliers in Total Square Footage')

# Floors
plt.subplot(2, 2, 4)
sns.boxplot(x=df_clean['floors'])
plt.title('Outliers in Number of Floors')

plt.tight_layout()

"""As i see outliers in the price bedrooms and sqft_total column so i will apply IQR method in it

The IQR-based outlier removal function calculates Q1 and Q3, then determines the interquartile range (IQR) and establishes lower and upper bounds at 1.5 times the IQR. It filters out values outside these limits. The loop applies this function to 'price', 'bedrooms', and 'sqft_total', effectively removing extreme outliers for improved quality.
"""

# Function to remove outliers using IQR method
def remove_outliers_iqr(dataframe, column):
    Q1 = dataframe[column].quantile(0.25)
    Q3 = dataframe[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    return dataframe[(dataframe[column] >= lower_bound) & (dataframe[column] <= upper_bound)]

# Apply outlier removal to relevant columns
for col in ['price', 'bedrooms', 'sqft_total']:
    df_clean = remove_outliers_iqr(df_clean, col)

# Box plots to display outliers in 'price', 'bedrooms', 'sqft_total', and 'floors'
plt.figure(figsize=(12, 8))

# Price
plt.subplot(2, 2, 1)
sns.boxplot(x=df_clean['price'])
plt.title('Outliers in Price')

# Bedrooms
plt.subplot(2, 2, 2)
sns.boxplot(x=df_clean['bedrooms'])
plt.title('Outliers in Bedrooms')

# Sqft Total
plt.subplot(2, 2, 3)
sns.boxplot(x=df_clean['sqft_total'])
plt.title('Outliers in Total Square Footage')

# Floors
plt.subplot(2, 2, 4)
sns.boxplot(x=df_clean['floors'])
plt.title('Outliers in Number of Floors')

plt.tight_layout()

"""**Checking DataTypes** and **Data Wrangling**

This code snippet standardizes the data types in the DataFrame to ensure consistency for further analysis. We convert 'bedrooms' to integer and 'bathrooms' to float, treating 'floors', 'condition', 'grade', and 'renovated' as categorical variables. The 'built' column is also converted to integer. Next, we create the 'age' column by subtracting the 'built' year from 2025 and convert it to integer. These steps ensure that each column has the correct data type, which is essential for accurate analysis and modeling.
"""

df_clean['bedrooms'] = df_clean['bedrooms'].astype(int)
df_clean['bathrooms'] = df_clean['bathrooms'].astype(float)
df_clean['floors'] = df_clean['floors'].astype('category')
df_clean['condition'] = df_clean['condition'].astype('category')
df_clean['grade'] = df_clean['grade'].astype('category')
df_clean['built'] = df_clean['built'].astype(int)
df_clean['renovated'] = df_clean['renovated'].astype('category')
# Create the 'age' column before converting it
df_clean['age'] = 2025 - df_clean['built']
df_clean['age'] = df_clean['age'].astype(int)

df_clean.dtypes

"""# **Data View**"""

df_clean.head()

"""# **EDA (Exploratory Data Analysis)**

**Bedrooms vs Price Scatterplot**
"""

plt.figure(figsize=(8, 5))
sns.violinplot(data=df_clean, x='bedrooms', y='price', inner="quart", palette="Set3")
plt.title('Violin Plot: Price Distribution by Bedrooms')
plt.xlabel('Bedrooms')
plt.ylabel('Price')
plt.tight_layout()

"""**Observation:**

* The price distribution is wider for properties with 3, 4, and 5 bedrooms, indicating more price variability.
* Median prices increase slightly from 2 to 5 bedrooms, but some overlap suggests that more bedrooms do not always mean higher prices.
* Some multimodal peaks suggest multiple price segments within the same bedroom count.
"""

# Floors vs Sqft Total - Average sqft_total per floor level
avg_sqft_by_floors = df_clean.groupby('floors')['sqft_total'].mean().reset_index()

plt.figure(figsize=(8, 5))
sns.barplot(data=avg_sqft_by_floors, x='floors', y='sqft_total')
plt.title('Average Total Sqft by Number of Floors')
plt.xlabel('Number of Floors')
plt.ylabel('Average Total Sqft')
plt.tight_layout()
plt.show()

"""**Observation:**

* Houses with 1 floor have the highest average total square footage, possibly due to sprawling single-story homes.
* 1.5 and 2 floors have slightly smaller averages, while 3+ floors sharply decrease, indicating rarity or compact urban builds.
* This may reflect design preferences or space constraints in vertical construction.
"""

# Average Price of the house with respect to its age
df_clean.groupby("age")["price"].mean().plot(kind='bar', figsize=(20,5))

"""**Observation:**

1. Prices generally decline with age up to a certain point (~age 70–80), reflecting depreciation.
2. However, older homes (90+ years) often maintain or increase in price, likely due to historic or renovated properties.
3. Indicates that not all old houses are cheap; some may hold value due to location or architecture.
"""

# Line Plot: Average Sqft Living by Grade
plt.figure(figsize=(8, 5))
grade_sqft = df_clean.groupby('grade')['sqft_living'].mean().reset_index()
sns.lineplot(data=grade_sqft, x='grade', y='sqft_living', marker="o")
plt.title("Average Living Area (Sqft) by Grade")
plt.xlabel("Grade")
plt.ylabel("Average Sqft Living")
plt.tight_layout()

"""**Observation:**

* Strong positive correlation between grade and average living area (sqft).
* Higher-grade properties are significantly larger.
* Suggests that grade is a composite measure involving size, finish, and design quality.
"""

# Barplot: Count of Houses per Floor Level
plt.figure(figsize=(8, 5))
sns.countplot(data=df_clean, x='floors')
plt.title("Number of Houses by Floor Count")
plt.xlabel("Floors")
plt.ylabel("Number of Houses")
plt.tight_layout()

"""**Observation:**

* Most homes are single-story (1 floor), indicating a market preference or zoning characteristic.
* 2-floor homes are also common, but 3+ floors are very rare, likely due to cost, space limitations, or regulation.
* Could suggest targeted design for a suburban or flat region.
"""

# Boxplot: Price distribution by Condition
plt.figure(figsize=(8, 5))
sns.boxplot(data=df_clean, x='condition', y='price')
plt.title("Price Distribution by Condition")
plt.xlabel("Condition")
plt.ylabel("Price")
plt.tight_layout()

"""**Observation:**

* Better condition (4–5) properties tend to have higher price medians.
* Condition 3 is most common but spans a wide price range.
* Condition 1–2 properties are less expensive, with a few outliers possibly skewed by location or renovation.
"""

# Heatmap of correlation
plt.figure(figsize=(10, 8))
correlation_matrix = df_clean.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix')
plt.tight_layout()
plt.show()

"""### **Key Observations**

Strong positive correlations:

sqft_living and bathrooms: 0.71 – Bigger homes have more bathrooms.

sqft_living and living_area_sqft: 0.74 – Very closely related.

sqft_living and price: 0.59 – Larger homes tend to cost more.

bathrooms and price: 0.42 – More bathrooms generally increase property value.

bedrooms and sqft_living: 0.60 – More bedrooms usually mean more space.

Moderate/weak correlation:

bedrooms and price: 0.28 – Bedroom count alone has limited impact on price.

Negative correlations:

age and bathrooms: -0.54 – Older homes tend to have fewer bathrooms.

age and living_area_sqft: -0.37 – Older homes are typically smaller.

age and built: -1.00 – Perfect inverse relationship (by design).

Minimal correlation:

sqft_total and price: 0.01 – Lot size has little influence on price.

built and price: -0.01 – Year built does not significantly affect value.

# **Checking for trends of prices from the Dataset**
"""

from io import StringIO
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler

# Select features and target
# Select all relevant numeric features (excluding target 'price')
features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_total',
            'floors', 'condition', 'grade', 'built', 'renovated', 'living_area_sqft', 'age']
X = df_clean[features]
y = df_clean['price']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Fit linear regression model
full_model = LinearRegression()
full_model.fit(X_train_scaled, y_train)

# Predict and evaluate
y_pred_full = full_model.predict(X_test_scaled)
r2_full = r2_score(y_test, y_pred_full)

# Display coefficients with feature names
coefficients = pd.DataFrame({
    'Feature': features,
    'Coefficient': full_model.coef_
}).sort_values(by='Coefficient', ascending=False)

r2_full, coefficients

# Visualizing the predicted vs actual prices for the full feature model
plt.figure(figsize=(8, 5))
plt.scatter(y_test, y_pred_full, color='blue', alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Ideal Prediction')
plt.title(f'Predicted vs Actual House Prices (All Features)\nR² = {r2_full:.2f}')
plt.xlabel('Actual Price')
plt.ylabel('Predicted Price')
plt.legend()
plt.tight_layout()

#trend_graph_path

"""### **Future Trends Observation**
The model shows a moderate prediction accuracy with an R² score of 0.58.

Grade, sqft_living, and living area are the top positive indicators of price growth.

Newer, high-grade, and spacious homes are likely to appreciate more in the future.

The prediction graph confirms a clear upward trend in housing prices.

Land size and build year have lesser or negative influence on price.

"""